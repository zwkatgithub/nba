{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy\n",
    "from sklearn import datasets, linear_model\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open( '/home/xdzw/Download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xList = []\n",
    "labels = []\n",
    "names = []\n",
    "firstLine = True\n",
    "for line in data.text.strip().split('\\n'):\n",
    "    if firstLine:\n",
    "        names = line.strip().split(\";\")\n",
    "        firstLine = False\n",
    "    else:\n",
    "        row = line.strip().split(';')\n",
    "        labels.append(float(row[-1]))\n",
    "        row.pop()\n",
    "        floatROw = [float(n) for n in row]\n",
    "        xList.append(floatRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label2idx = dict(\n",
    "    {'PF':0, 'C':1, 'SF':2, 'SG':3, 'PG':4}\n",
    ")\n",
    "idx2label = {v:k for v,k in label2idx.items()}\n",
    "\n",
    "def readData(dataFile):\n",
    "    with open(dataFile, 'r') as f:\n",
    "        table = json.load(f)\n",
    "    return pd.DataFrame(table[1:],columns=table[0]).fillna(0.0)\n",
    "def std(data,mean):\n",
    "    return nd.sum((data - mean)**2, axis=0)/data.shape[0]\n",
    "def preProcessData(data):\n",
    "    dataScaled = preprocessing.scale(data.asnumpy(), axis=0)\n",
    "    return nd.array(dataScaled)\n",
    "def processLabel(y):\n",
    "    # labels = []\n",
    "    # for label in y:\n",
    "    #     if '-' in label:\n",
    "    #         label = label.split('-')\n",
    "    #         ll = [0.0]*5\n",
    "    #         for l in label:\n",
    "    #             ll[lable2idx[l]] = 0.5\n",
    "    #         labels.append(ll)\n",
    "    #     else:\n",
    "    #         l = [0.0]*5\n",
    "    #         l[lable2idx[label]] = 1.0\n",
    "    #         labels.append(l)\n",
    "    # return labels\n",
    "    labels = []\n",
    "    for label in y:\n",
    "        if '-' in label:\n",
    "            labels.append(label2idx[label.split('-')[0]])\n",
    "        else:\n",
    "            labels.append(label2idx[label])\n",
    "    return labels\n",
    "        \n",
    "\n",
    "def divideTrainTest(x,y, rate):\n",
    "    n = int(len(x)*rate)\n",
    "    return (x[0:n], y[0:n]), (x[n:], y[n:])\n",
    "\n",
    "def data_iter(x,y,batch_size):\n",
    "    n = len(x)\n",
    "    idx = list(range(n))\n",
    "    np.random.shuffle(idx)\n",
    "    for i in range(0,n,batch_size):\n",
    "        j = nd.array(idx[i:min(i+batch_size, n)])\n",
    "        yield nd.take(x, j), nd.take(y, j)\n",
    "\n",
    "def accuracy(output,label):\n",
    "    \"\"\"\n",
    "        output : [1,2,3,4,5], label : 2\n",
    "    \"\"\"\n",
    "    labelHat = nd.argmax(output, axis=1)\n",
    "    return sum(labelHat == label) / output.shape[0]\n",
    "\n",
    "def evaluate_accuracy(x,y,net):\n",
    "    labelHat = net(x)\n",
    "    return accuracy(labelHat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataFile = '/home/xdzwk/project/data/nba_data.txt'\n",
    "    data = readData(dataFile)\n",
    "    #print(len(dict(zip(processLabel(data.iloc[:,0]),processLabel(data.iloc[:,0])))))\n",
    "    x = preProcessData(nd.array(data.iloc[:,1:]))\n",
    "    y = nd.array(processLabel(data.iloc[:,0]))\n",
    "    train_data, test_data = divideTrainTest(x,y,0.8)\n",
    "\n",
    "    batch_size = 10\n",
    "\n",
    "    net = gluon.nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(gluon.nn.Dense(30, activation='relu'))\n",
    "        net.add(gluon.nn.Dense(5))\n",
    "    net.initialize()\n",
    "\n",
    "    lossFunc = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate':0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = nd.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8834612"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(x.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Loss: 0.016473659433512693, Train acc: 0.0017404467172206924, Test acc 0.2023681402206421\n",
      "Epoch 1 : Loss: 0.01644498324753522, Train acc: 0.002357373507322485, Test acc 0.23035521805286407\n",
      "Epoch 2 : Loss: 0.016429437663249745, Train acc: 0.002330462858321464, Test acc 0.21420882642269135\n",
      "Epoch 3 : Loss: 0.016408631183102776, Train acc: 0.0023069160401949455, Test acc 0.21097955107688904\n",
      "Epoch 4 : Loss: 0.01639405569809502, Train acc: 0.002402448856278821, Test acc 0.21636168658733368\n",
      "Epoch 5 : Loss: 0.01638123595162793, Train acc: 0.002452233587707462, Test acc 0.2152852565050125\n",
      "Epoch 6 : Loss: 0.016363646678698718, Train acc: 0.0025114370279407093, Test acc 0.22389666736125946\n",
      "Epoch 7 : Loss: 0.016341516096445664, Train acc: 0.002564585568188851, Test acc 0.2292787879705429\n",
      "Epoch 8 : Loss: 0.01632638267603321, Train acc: 0.002629171174713305, Test acc 0.24219590425491333\n",
      "Epoch 9 : Loss: 0.01630506955640565, Train acc: 0.002687029051318749, Test acc 0.2529601752758026\n",
      "Epoch 10 : Loss: 0.01627701723023816, Train acc: 0.0027872712679199306, Test acc 0.2529601752758026\n",
      "Epoch 11 : Loss: 0.016257886064065415, Train acc: 0.002890204515536712, Test acc 0.2680301368236542\n",
      "Epoch 12 : Loss: 0.016237829838938553, Train acc: 0.002962190541564071, Test acc 0.28202366828918457\n",
      "Epoch 13 : Loss: 0.01622023816000915, Train acc: 0.0029662271201674724, Test acc 0.2841765284538269\n",
      "Epoch 14 : Loss: 0.016199237531686624, Train acc: 0.003110199148162189, Test acc 0.293864369392395\n",
      "Epoch 15 : Loss: 0.01618943340170114, Train acc: 0.0031546017413696253, Test acc 0.3046286404132843\n",
      "Epoch 16 : Loss: 0.016140976814458908, Train acc: 0.0033026103279177417, Test acc 0.3143164813518524\n",
      "Epoch 17 : Loss: 0.016107060488381605, Train acc: 0.003317411219053556, Test acc 0.3261571526527405\n",
      "Epoch 18 : Loss: 0.01607299402789228, Train acc: 0.0033315393323854687, Test acc 0.32723358273506165\n",
      "Epoch 19 : Loss: 0.01604830028551387, Train acc: 0.003406889147182327, Test acc 0.34122711420059204\n",
      "Epoch 20 : Loss: 0.016008875758835264, Train acc: 0.0034997309282406024, Test acc 0.34768569469451904\n",
      "Epoch 21 : Loss: 0.015951985595557352, Train acc: 0.003567007541720654, Test acc 0.3552206754684448\n",
      "Epoch 22 : Loss: 0.01588628985653396, Train acc: 0.003663885909402332, Test acc 0.3530678153038025\n",
      "Epoch 23 : Loss: 0.015818070896988407, Train acc: 0.0037466361677620974, Test acc 0.356297105550766\n",
      "Epoch 24 : Loss: 0.015776062454422785, Train acc: 0.0037486544610737986, Test acc 0.3659849166870117\n",
      "Epoch 25 : Loss: 0.01568695530696372, Train acc: 0.0038468783522832765, Test acc 0.37459632754325867\n",
      "Epoch 26 : Loss: 0.015618106296167692, Train acc: 0.003918864346230633, Test acc 0.3864370286464691\n",
      "Epoch 27 : Loss: 0.015535792217572873, Train acc: 0.003966630780337573, Test acc 0.38858988881111145\n",
      "Epoch 28 : Loss: 0.015442341726485828, Train acc: 0.004037944032571031, Test acc 0.39289557933807373\n",
      "Epoch 29 : Loss: 0.015352925167401974, Train acc: 0.004076964471517261, Test acc 0.4004305601119995\n",
      "Epoch 30 : Loss: 0.015250358662384575, Train acc: 0.004210172239109569, Test acc 0.39935413002967834\n",
      "Epoch 31 : Loss: 0.015138552827906942, Train acc: 0.00420209900972276, Test acc 0.4015069901943207\n",
      "Epoch 32 : Loss: 0.015023843111596658, Train acc: 0.004197389633265455, Test acc 0.4015069901943207\n",
      "Epoch 33 : Loss: 0.014899309824819329, Train acc: 0.004268702909558915, Test acc 0.4079655408859253\n",
      "Epoch 34 : Loss: 0.014814186628719448, Train acc: 0.004220263701658075, Test acc 0.40904197096824646\n",
      "Epoch 35 : Loss: 0.014677335422955236, Train acc: 0.00421420880969297, Test acc 0.41227126121520996\n",
      "Epoch 36 : Loss: 0.014556902858746449, Train acc: 0.004192680280868152, Test acc 0.41550055146217346\n",
      "Epoch 37 : Loss: 0.014440232990119121, Train acc: 0.004235064572743887, Test acc 0.403659850358963\n",
      "Epoch 38 : Loss: 0.014326659451259863, Train acc: 0.004244483293578494, Test acc 0.40581271052360535\n",
      "Epoch 39 : Loss: 0.014182985181829004, Train acc: 0.004272066722388416, Test acc 0.4079655408859253\n",
      "Epoch 40 : Loss: 0.014045883399164715, Train acc: 0.004288885874755929, Test acc 0.40581271052360535\n",
      "Epoch 41 : Loss: 0.013979136815497128, Train acc: 0.004285522069946429, Test acc 0.4015069901943207\n",
      "Epoch 42 : Loss: 0.013866579314479273, Train acc: 0.004307050590751245, Test acc 0.4101184010505676\n",
      "Epoch 43 : Loss: 0.013751901870651574, Train acc: 0.004298304619650538, Test acc 0.4079655408859253\n",
      "Epoch 44 : Loss: 0.01363021680690244, Train acc: 0.004361544634477186, Test acc 0.4101184010505676\n",
      "Epoch 45 : Loss: 0.013532888645504724, Train acc: 0.004399892339729519, Test acc 0.41227126121520996\n",
      "Epoch 46 : Loss: 0.013426029354943398, Train acc: 0.004409311092644128, Test acc 0.41334769129753113\n",
      "Epoch 47 : Loss: 0.013358003035813281, Train acc: 0.004385091460623705, Test acc 0.41657695174217224\n",
      "Epoch 48 : Loss: 0.013240360790228048, Train acc: 0.004482642586059283, Test acc 0.4208826720714569\n",
      "Epoch 49 : Loss: 0.01313842760862139, Train acc: 0.004457750236384964, Test acc 0.43595263361930847\n"
     ]
    }
   ],
   "source": [
    "    for e in range(50):\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        for data, label in data_iter(train_data[0], \n",
    "            train_data[1],batch_size):\n",
    "            with autograd.record():\n",
    "                output = net(data)\n",
    "                loss = lossFunc(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "            train_acc += accuracy(output, label).asscalar()\n",
    "        \n",
    "        test_acc = evaluate_accuracy(test_data[0], test_data[1], net).asscalar()\n",
    "        print(\"Epoch {0} : Loss: {1}, Train acc: {2}, Test acc {3}\".format(\n",
    "            e, train_loss/len(train_data[0]), train_acc/len(train_data[0]), test_acc)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
